TAG: FlareLuma-run1
SEED: 7
COMMENT: "FiLM applied on all stages"

DATA:
  PIN_MEMORY: False
  NAME: "DIV2K+Flickr2K"
  LOCATIONS:
    TRAIN:  ["data/DIV2K/DIV2K_train_HR", "data/Flickr2K/"]
    VAL:    ["data/DIV2K/DIV2K_valid_HR/"]
    TEST:   ["data/live1/refimgs/"]
  PATCH_SIZE: 128
  REGION_SIZE: -1
  NUM_PATCHES: 16
  SUBSAMPLE: 444
  MIN_QUALITY: 10
  MAX_QUALITY: 90
  TARGET_QUALITY: 100
  CACHED: False
  CACHE_MEMORY: 32
  USE_LQ_RGB: False
  USE_LQ_YCC: True
  USE_LQ_DCT: True
  USE_HQ_RGB: False
  USE_HQ_YCC: True
  USE_HQ_DCT: False
  USE_QTABLES: True
  NORMALIZE_RGB: False
  NORMALIZE_YCC: False
  NORMALIZE_DCT: True
  INVERT_QT: True
  DCT_STATS_FILEPATH: "data/DIV2K+Flickr2K-dct-stats.json"
  PIN_MEMORY: False
  PIN_MEMORY_DEVICE: ''
  SHUFFLE: True
  NUM_WORKERS: 0
MODEL:
  NAME: FlareLuma
  CLASS: FlareLuma
  FLARE:
    LUMA:
      KWARGS: [[residual, True], [base_channels, 32], [blocks_per_stage, 1], [channel_multiplier, 2]]
TRAIN:
  DEVICE: "mps"
  BATCH_SIZE: 64
  NUM_ITERATIONS: 100_000
  WARMUP_ITERATIONS: 1000
  CLIP_GRAD: 10.0
  CLIP_GRAD_METHOD: "total"
  BASE_LR: 2.0e-4
  WARMUP_LR: 1.0e-5
  LR_SCHEDULER:
    NAME: cosine
    KWARGS: [[T_0, 99_000], [eta_min, 1.0e-5], [T_mult, 2]]
    WARMUP_PREFIX: True
  CHECKPOINT_EVERY: 500
  CHECKPOINT_DIR: /Volumes/SiliconPower/jpeg-deblock/checkpoints/
VALIDATION:
  BATCH_SIZE: 64
  EVERY: 250
  QUALITIES: [10, 20, 40, 60]
TEST:
  BATCH_SIZE: 1
  QUALITIES: [10, 20, 40, 60, 80]
  REGION_SIZE: 512
LOGGING:
  DIR: /Volumes/SiliconPower/jpeg-deblock/logs
  LOG_EVERY: 50
  WANDB: False
  PLOTS: True
